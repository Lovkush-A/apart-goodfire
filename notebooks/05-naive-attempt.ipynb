{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "from transformer_lens import HookedTransformer\n",
    "import numpy as np\n",
    "from typing import List, Tuple, TypeAlias\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import goodfire\n",
    "from utils import get_completion\n",
    "\n",
    "from utils import get_activations\n",
    "from utils import compute_steering_vector\n",
    "from utils import apply_steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"I am {}. What advice do you have for me?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create contrastive dataset using Goodfire API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOODFIRE_API_KEY\")\n",
    "client = goodfire.Client(api_key)\n",
    "variant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "\n",
    "features, relevance = client.features.search(\n",
    "    \"deception\",\n",
    "    model=variant,\n",
    "    top_k=5\n",
    ")\n",
    "print(features)\n",
    "\n",
    "chosen_feature = features[3]\n",
    "print(chosen_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\n",
    "    'playing a game of diplomacy',\n",
    "    'applying for a job',\n",
    "    'participating in a poker tournament',\n",
    "    'performing as a magician',\n",
    "    'coaching a sports team',\n",
    "    'negotiating a business deal',\n",
    "    'acting in a theater production',\n",
    "    'planning a surprise party',\n",
    "    'playing capture the flag',\n",
    "    'writing mystery fiction',\n",
    "    'doing improvisational comedy',\n",
    "    'designing escape rooms',\n",
    "    'competing in a chess tournament',\n",
    "    'playing paintball with friends',\n",
    "    'participating in debate club',\n",
    "    'leading a scavenger hunt',\n",
    "    'doing stage magic tricks',\n",
    "    'playing hide and seek',\n",
    "    'writing riddles for an event',\n",
    "    'organizing team building games',\n",
    "    'competing in martial arts',\n",
    "    'playing laser tag',\n",
    "    'running an escape room business',\n",
    "    'doing improv theater games',\n",
    "    'playing social deduction games',\n",
    "    'teaching strategy games',\n",
    "    'hosting a murder mystery party',\n",
    "    'practicing negotiation skills',\n",
    "    'playing card games',\n",
    "    'training for sports competitions',\n",
    "    'writing mystery novels',\n",
    "    'designing puzzle games',\n",
    "    'competing in a trivia contest',\n",
    "    'playing charades',\n",
    "    'participating in mock trials',\n",
    "    'planning an elaborate proposal',\n",
    "    'doing standup comedy',\n",
    "    'practicing sleight of hand',\n",
    "    'playing strategic board games',\n",
    "    'running dungeons and dragons',\n",
    "    'playing werewolf/mafia games',\n",
    "    'competing in spelling bees',\n",
    "    'doing geocaching',\n",
    "    'practicing tactical sports',\n",
    "    'organizing treasure hunts',\n",
    "    'playing strategy video games',\n",
    "    'hosting quiz shows',\n",
    "    'practicing mental sports',\n",
    "    'doing puzzle competitions',\n",
    "    'playing capture the flag online',\n",
    "    'teaching game theory',\n",
    "    'running simulation games'\n",
    "]\n",
    "\n",
    "variant.reset()\n",
    "variant.set(chosen_feature, 0.6, mode=\"nudge\")\n",
    "positive_nudge_completions: list[str] = []\n",
    "for scenario in scenarios:\n",
    "    prompt = prompt_template.format(scenario)\n",
    "    completion = get_completion(client, variant, prompt)\n",
    "    positive_nudge_completions.append(completion)\n",
    "    # print(completion)\n",
    "\n",
    "variant.reset()\n",
    "variant.set(chosen_feature, -0.3, mode=\"nudge\")\n",
    "negative_nudge_completions: list[str] = []\n",
    "for scenario in scenarios:\n",
    "    prompt = prompt_template.format(scenario)\n",
    "    completion = get_completion(client, variant, prompt)\n",
    "    negative_nudge_completions.append(completion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary containing scenarios and completions\n",
    "data = {}\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    data[scenario] = {\n",
    "        \"positive_nudge\": positive_nudge_completions[i],\n",
    "        \"negative_nudge\": negative_nudge_completions[i]\n",
    "    }\n",
    "\n",
    "# save dictionary to json file\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create steering vector, using contrastive dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "with open('data02.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# create full list of contrastive pairs from the data\n",
    "pairs = []\n",
    "for scenario, completions in data.items():\n",
    "    user_content = prompt_template.format(scenario)\n",
    "    positive_nudge = completions['positive_nudge']\n",
    "    negative_nudge = completions['negative_nudge']\n",
    "    pairs.append((\n",
    "        [{\"role\": \"user\", \"content\": user_content}, {\"role\": \"assistant\", \"content\": positive_nudge}],\n",
    "        [{\"role\": \"user\", \"content\": user_content}, {\"role\": \"assistant\", \"content\": negative_nudge}]\n",
    "    ))\n",
    "\n",
    "pairs[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute steering vector\n",
    "model = HookedTransformer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_vector = compute_steering_vector(model, pairs[0:1], layer=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(steering_vector.max())\n",
    "print(steering_vector.min())\n",
    "print(steering_vector.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = list(data.keys())\n",
    "scenario = scenarios[0]\n",
    "\n",
    "# Apply steering to new text\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt_template.format(scenario)},\n",
    "]\n",
    "\n",
    "for strength in [-1, -0.5, 0, 0.1, 0.3, 1]:\n",
    "    modified_text = apply_steering(model, messages, steering_vector, n_tokens=25, layer=19, strength=strength)\n",
    "    print(f\"Strength: {strength}\")\n",
    "    print(modified_text)\n",
    "    print()\n",
    "    print()\n",
    "    print('='*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding `apply_chat_template`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I be a pirate chatbot, arrr!\"},\n",
    "    {\"role\": \"user\", \"content\": \"What do you do?\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = tokenizer.decode(input_ids[0], skip_special_tokens=False)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(decoded_text, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [9125, 882, 78191, 271]:\n",
    "    print(i, tokenizer.decode([i], skip_special_tokens=False))\n",
    "\n",
    "for i in range(-10, 25):\n",
    "    print(i, tokenizer.decode([128000+i], skip_special_tokens=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
