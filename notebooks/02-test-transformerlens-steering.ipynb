{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformer_lens import HookedTransformer\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "def get_activations(\n",
    "    model: HookedTransformer,\n",
    "    text: str,\n",
    "    layer: int = -1,\n",
    "    pos: int = -1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Get activations at a specific layer and position.\"\"\"\n",
    "    tokens = model.to_tokens(text)\n",
    "    _, cache = model.run_with_cache(tokens)\n",
    "    # Get residual stream activations at specified layer\n",
    "    activations = cache[\"resid_post\", layer][0]\n",
    "    # If pos is -1, average across all positions, otherwise take specific position\n",
    "    if pos == -1:\n",
    "        return activations.mean(dim=0)\n",
    "    return activations[pos]\n",
    "\n",
    "def compute_steering_vector(\n",
    "    model: HookedTransformer,\n",
    "    pairs: List[Tuple[str, str]],\n",
    "    layer: int = -1,\n",
    "    pos: int = -1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute steering vector from contrastive pairs.\n",
    "    \n",
    "    Args:\n",
    "        model: HookedTransformer model\n",
    "        pairs: List of (x, y) sentence pairs\n",
    "        layer: Layer to extract activations from (-1 for final layer)\n",
    "        pos: Position to extract activations from (-1 to average across positions)\n",
    "    \n",
    "    Returns:\n",
    "        Steering vector as torch tensor\n",
    "    \"\"\"\n",
    "    # Get activations for each sentence in pairs\n",
    "    x_activations = []\n",
    "    y_activations = []\n",
    "    \n",
    "    for x, y in pairs:\n",
    "        x_act = get_activations(model, x, layer, pos)\n",
    "        y_act = get_activations(model, y, layer, pos)\n",
    "        \n",
    "        x_activations.append(x_act)\n",
    "        y_activations.append(y_act)\n",
    "    \n",
    "    # Stack activations\n",
    "    x_activations = torch.stack(x_activations)\n",
    "    y_activations = torch.stack(y_activations)\n",
    "    \n",
    "    # Compute difference vectors\n",
    "    diff_vectors = y_activations - x_activations\n",
    "    \n",
    "    # Average difference vectors to get steering vector\n",
    "    steering_vector = diff_vectors.mean(dim=0)\n",
    "    \n",
    "    # Normalize steering vector\n",
    "    steering_vector = steering_vector / torch.norm(steering_vector)\n",
    "    \n",
    "    return steering_vector\n",
    "\n",
    "def apply_steering(\n",
    "    model: HookedTransformer,\n",
    "    prefix: str,\n",
    "    steering_vector: torch.Tensor,\n",
    "    n_tokens: int,\n",
    "    layer: int = -1,\n",
    "    strength: float = 1.0\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Apply steering vector to generate text from a prefix.\n",
    "    \n",
    "    Args:\n",
    "        model: HookedTransformer model\n",
    "        prefix: Input text prefix to start generation\n",
    "        steering_vector: Computed steering vector\n",
    "        n_tokens: Number of tokens to generate\n",
    "        layer: Layer to apply steering at\n",
    "        strength: Scaling factor for steering vector\n",
    "    \n",
    "    Returns:\n",
    "        Generated text after applying steering\n",
    "    \"\"\"\n",
    "    tokens = model.to_tokens(prefix)\n",
    "    \n",
    "    def hook_fn(activations, hook):\n",
    "        # Add scaled steering vector to residual stream\n",
    "        return activations + strength * steering_vector\n",
    "    \n",
    "    # Register hook at specified layer\n",
    "    hook_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "    \n",
    "    generated_tokens = tokens\n",
    "    for _ in range(n_tokens):\n",
    "        logits = model.run_with_hooks(\n",
    "            generated_tokens,\n",
    "            fwd_hooks=[(hook_name, hook_fn)]\n",
    "        )\n",
    "        next_token = logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "        generated_tokens = torch.cat((generated_tokens, next_token), dim=1)\n",
    "    \n",
    "    # Convert generated tokens to text\n",
    "    return model.to_string(generated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-medium into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "# Example contrastive pairs\n",
    "pairs = [\n",
    "    (\"The movie was bad\", \"The movie was good\"),\n",
    "    (\"This restaurant is terrible\", \"This restaurant is excellent\"),\n",
    "    (\"I dislike the book\", \"I love the book\")\n",
    "]\n",
    "\n",
    "# Compute steering vector\n",
    "steering_vector = compute_steering_vector(model, pairs, layer=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strength: -1000, Modified: ['<|endoftext|>I think movie was Gh Gh Gh Gh Gh']\n",
      "Strength: -300, Modified: ['<|endoftext|>I think movie was, but the the the']\n",
      "Strength: -100, Modified: ['<|endoftext|>I think movie was a bad thing, but']\n",
      "Strength: -30, Modified: ['<|endoftext|>I think movie was a good idea.\\n']\n",
      "Strength: -10, Modified: ['<|endoftext|>I think movie was a good idea. I']\n",
      "Strength: 10, Modified: ['<|endoftext|>I think movie was a bit of a disappointment']\n",
      "Strength: 30, Modified: ['<|endoftext|>I think movie was a bit of a disappointment']\n",
      "Strength: 50, Modified: ['<|endoftext|>I think movie was a great idea. I']\n",
      "Strength: 80, Modified: ['<|endoftext|>I think movie was a great way to celebrate']\n",
      "Strength: 100, Modified: ['<|endoftext|>I think movie was made by the police officers']\n",
      "Strength: 300, Modified: ['<|endoftext|>I think movie was the the the the the']\n"
     ]
    }
   ],
   "source": [
    "# Apply steering to new text\n",
    "test_text = \"I think movie was\"\n",
    "\n",
    "for strength in [-1000, -300, -100, -30, -10, 10, 30, 50, 80, 100, 300]:\n",
    "    modified_text = apply_steering(model, test_text, steering_vector, n_tokens=5, layer=6, strength=strength)\n",
    "    print(f\"Strength: {strength}, Modified: {modified_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
